{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "##### Flat Acquisition using csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('./data/movies.csv')\n",
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "tags = pd.read_csv('./data/tags.csv')\n",
    "genome_scores = pd.read_csv('./data/genome-scores.csv')\n",
    "genome_tags = pd.read_csv('./data/genome-tags.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      296     5.0  1147880044\n",
       "1       1      306     3.5  1147868817\n",
       "2       1      307     5.0  1147868828\n",
       "3       1      665     5.0  1147878820\n",
       "4       1      899     3.5  1147868510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>classic</td>\n",
       "      <td>1439472355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>260</td>\n",
       "      <td>sci-fi</td>\n",
       "      <td>1439472256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1732</td>\n",
       "      <td>dark comedy</td>\n",
       "      <td>1573943598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1732</td>\n",
       "      <td>great dialogue</td>\n",
       "      <td>1573943604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7569</td>\n",
       "      <td>so bad it's good</td>\n",
       "      <td>1573943455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId               tag   timestamp\n",
       "0       3      260           classic  1439472355\n",
       "1       3      260            sci-fi  1439472256\n",
       "2       4     1732       dark comedy  1573943598\n",
       "3       4     1732    great dialogue  1573943604\n",
       "4       4     7569  so bad it's good  1573943455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genome Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  tagId  relevance\n",
       "0        1      1    0.02875\n",
       "1        1      2    0.02375\n",
       "2        1      3    0.06250\n",
       "3        1      4    0.07575\n",
       "4        1      5    0.14075"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genome Tags:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>007 (series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1920s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tagId           tag\n",
       "0      1           007\n",
       "1      2  007 (series)\n",
       "2      3  18th century\n",
       "3      4         1920s\n",
       "4      5         1930s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print the first 5 rows of the csv files\n",
    "print('Movies:')\n",
    "display(movies.head())\n",
    "print('Ratings:')\n",
    "display(ratings.head())\n",
    "print('Tags:')\n",
    "display(tags.head())\n",
    "print('Genome Scores:')\n",
    "display(genome_scores.head())\n",
    "print('Genome Tags:')\n",
    "display(genome_tags.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>3.893708</td>\n",
       "      <td>57309</td>\n",
       "      <td>1153152210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>3.251527</td>\n",
       "      <td>24228</td>\n",
       "      <td>1122310117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>3.142028</td>\n",
       "      <td>11804</td>\n",
       "      <td>980602256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>2.853547</td>\n",
       "      <td>2523</td>\n",
       "      <td>942460471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3.058434</td>\n",
       "      <td>11714</td>\n",
       "      <td>1004723013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  mean_rating  rating_count  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy     3.893708         57309   \n",
       "1                   Adventure|Children|Fantasy     3.251527         24228   \n",
       "2                               Comedy|Romance     3.142028         11804   \n",
       "3                         Comedy|Drama|Romance     2.853547          2523   \n",
       "4                                       Comedy     3.058434         11714   \n",
       "\n",
       "   mean_timestamp  \n",
       "0      1153152210  \n",
       "1      1122310117  \n",
       "2       980602256  \n",
       "3       942460471  \n",
       "4      1004723013  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ratings group by movieId with mean and count\n",
    "grouped_ratings = ratings.groupby('movieId').agg({'rating': ['mean', 'count'], 'timestamp': ['mean']})\n",
    "grouped_ratings.columns = ['mean_rating', 'rating_count', 'mean_timestamp']\n",
    "grouped_ratings = grouped_ratings.astype({'mean_timestamp': 'int'})\n",
    "\n",
    "# Dataset merge with movies and ratings, with missing rating films removed\n",
    "df = pd.merge(movies, grouped_ratings, on='movieId')\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_timestamp</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adapted from:book</th>\n",
       "      <th>...</th>\n",
       "      <th>visceral</th>\n",
       "      <th>visual</th>\n",
       "      <th>visually appealing</th>\n",
       "      <th>visually stunning</th>\n",
       "      <th>weapons</th>\n",
       "      <th>weird</th>\n",
       "      <th>whimsical</th>\n",
       "      <th>witty</th>\n",
       "      <th>women</th>\n",
       "      <th>writers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>3.893708</td>\n",
       "      <td>57309</td>\n",
       "      <td>1153152210</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.66250</td>\n",
       "      <td>0.31675</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.56375</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.67325</td>\n",
       "      <td>0.26375</td>\n",
       "      <td>0.42700</td>\n",
       "      <td>0.58700</td>\n",
       "      <td>0.69400</td>\n",
       "      <td>0.08925</td>\n",
       "      <td>0.14125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>3.251527</td>\n",
       "      <td>24228</td>\n",
       "      <td>1122310117</td>\n",
       "      <td>0.15925</td>\n",
       "      <td>0.64025</td>\n",
       "      <td>0.51450</td>\n",
       "      <td>0.48450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>0.38150</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.21700</td>\n",
       "      <td>0.17800</td>\n",
       "      <td>0.38650</td>\n",
       "      <td>0.29250</td>\n",
       "      <td>0.18725</td>\n",
       "      <td>0.13525</td>\n",
       "      <td>0.12225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>3.142028</td>\n",
       "      <td>11804</td>\n",
       "      <td>980602256</td>\n",
       "      <td>0.11375</td>\n",
       "      <td>0.16025</td>\n",
       "      <td>0.25200</td>\n",
       "      <td>0.19375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10175</td>\n",
       "      <td>0.10725</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.09850</td>\n",
       "      <td>0.14125</td>\n",
       "      <td>0.24350</td>\n",
       "      <td>0.13025</td>\n",
       "      <td>0.22325</td>\n",
       "      <td>0.35075</td>\n",
       "      <td>0.12200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>2.853547</td>\n",
       "      <td>2523</td>\n",
       "      <td>942460471</td>\n",
       "      <td>0.13375</td>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.50700</td>\n",
       "      <td>0.46175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08800</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.11625</td>\n",
       "      <td>0.28950</td>\n",
       "      <td>0.21975</td>\n",
       "      <td>0.14775</td>\n",
       "      <td>0.10725</td>\n",
       "      <td>0.97525</td>\n",
       "      <td>0.18200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3.058434</td>\n",
       "      <td>11714</td>\n",
       "      <td>1004723013</td>\n",
       "      <td>0.15475</td>\n",
       "      <td>0.15575</td>\n",
       "      <td>0.28925</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.11925</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.11875</td>\n",
       "      <td>0.12025</td>\n",
       "      <td>0.29350</td>\n",
       "      <td>0.16425</td>\n",
       "      <td>0.10475</td>\n",
       "      <td>0.40225</td>\n",
       "      <td>0.19225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  mean_rating  rating_count  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy     3.893708         57309   \n",
       "1                   Adventure|Children|Fantasy     3.251527         24228   \n",
       "2                               Comedy|Romance     3.142028         11804   \n",
       "3                         Comedy|Drama|Romance     2.853547          2523   \n",
       "4                                       Comedy     3.058434         11714   \n",
       "\n",
       "   mean_timestamp   absurd   action  adaptation  adapted from:book  ...  \\\n",
       "0      1153152210  0.10400  0.66250     0.31675            0.28600  ...   \n",
       "1      1122310117  0.15925  0.64025     0.51450            0.48450  ...   \n",
       "2       980602256  0.11375  0.16025     0.25200            0.19375  ...   \n",
       "3       942460471  0.13375  0.14700     0.50700            0.46175  ...   \n",
       "4      1004723013  0.15475  0.15575     0.28925            0.19800  ...   \n",
       "\n",
       "   visceral   visual  visually appealing  visually stunning  weapons    weird  \\\n",
       "0   0.15150  0.56375              0.3150            0.67325  0.26375  0.42700   \n",
       "1   0.07325  0.38150              0.2250            0.21700  0.17800  0.38650   \n",
       "2   0.10175  0.10725              0.1960            0.09850  0.14125  0.24350   \n",
       "3   0.08800  0.10750              0.2115            0.11625  0.28950  0.21975   \n",
       "4   0.08275  0.11925              0.1850            0.11875  0.12025  0.29350   \n",
       "\n",
       "   whimsical    witty    women  writers  \n",
       "0    0.58700  0.69400  0.08925  0.14125  \n",
       "1    0.29250  0.18725  0.13525  0.12225  \n",
       "2    0.13025  0.22325  0.35075  0.12200  \n",
       "3    0.14775  0.10725  0.97525  0.18200  \n",
       "4    0.16425  0.10475  0.40225  0.19225  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by tagId and compute mean relevance\n",
    "mean_relevance = genome_scores.groupby('tagId').mean()['relevance']\n",
    "\n",
    "# Filter out tags with low mean relevance\n",
    "threshold = 0.2\n",
    "good_tags = mean_relevance.where(mean_relevance > threshold).dropna().index\n",
    "genome_scores_2 = genome_scores[genome_scores['tagId'].isin(good_tags)]\n",
    "\n",
    "# Merge movies with genome scores\n",
    "genome_scores_2['tag'] = genome_scores_2['tagId'].map(genome_tags.set_index('tagId')['tag'].to_dict())\n",
    "genome_table = genome_scores_2.pivot_table(index='movieId', columns='tag', values='relevance')\n",
    "\n",
    "# Merge movies with genome table\n",
    "df = pd.merge(df, genome_table, on='movieId')\n",
    "display(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation (Data cleaning, Duplicates filtering, Data encoding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  13816\n",
      "Number of rows after dropping missing values:  13816\n"
     ]
    }
   ],
   "source": [
    "# print number of rows\n",
    "print('Number of rows: ', df.shape[0])\n",
    "\n",
    "# fill rows with missing values (there are films with no tags, so we fill these tag columns set to 0)\n",
    "df = df.fillna(0)\n",
    "\n",
    "# print number of rows after dropping missing values\n",
    "print('Number of rows after dropping missing values: ', df.shape[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Encoding\n",
    "Multicategorical One-Hot encoding for film genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IMAX', 'Documentary', 'Romance', 'Thriller', 'Drama', 'War', 'Horror', 'Sci-Fi', 'Action', 'Fantasy', 'Film-Noir', 'Animation', 'Comedy', 'Children', 'Musical', 'Western', 'Adventure', 'Crime', 'Mystery'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_timestamp</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adapted from:book</th>\n",
       "      <th>adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Children</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Western</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Mystery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>3.893708</td>\n",
       "      <td>57309</td>\n",
       "      <td>1153152210</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.66250</td>\n",
       "      <td>0.31675</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>0.89375</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>3.251527</td>\n",
       "      <td>24228</td>\n",
       "      <td>1122310117</td>\n",
       "      <td>0.15925</td>\n",
       "      <td>0.64025</td>\n",
       "      <td>0.51450</td>\n",
       "      <td>0.48450</td>\n",
       "      <td>0.97600</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>3.142028</td>\n",
       "      <td>11804</td>\n",
       "      <td>980602256</td>\n",
       "      <td>0.11375</td>\n",
       "      <td>0.16025</td>\n",
       "      <td>0.25200</td>\n",
       "      <td>0.19375</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>2.853547</td>\n",
       "      <td>2523</td>\n",
       "      <td>942460471</td>\n",
       "      <td>0.13375</td>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.50700</td>\n",
       "      <td>0.46175</td>\n",
       "      <td>0.14875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>3.058434</td>\n",
       "      <td>11714</td>\n",
       "      <td>1004723013</td>\n",
       "      <td>0.15475</td>\n",
       "      <td>0.15575</td>\n",
       "      <td>0.28925</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.16350</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  mean_rating  rating_count  \\\n",
       "0        1                    Toy Story (1995)     3.893708         57309   \n",
       "1        2                      Jumanji (1995)     3.251527         24228   \n",
       "2        3             Grumpier Old Men (1995)     3.142028         11804   \n",
       "3        4            Waiting to Exhale (1995)     2.853547          2523   \n",
       "4        5  Father of the Bride Part II (1995)     3.058434         11714   \n",
       "\n",
       "   mean_timestamp   absurd   action  adaptation  adapted from:book  adventure  \\\n",
       "0      1153152210  0.10400  0.66250     0.31675            0.28600    0.89375   \n",
       "1      1122310117  0.15925  0.64025     0.51450            0.48450    0.97600   \n",
       "2       980602256  0.11375  0.16025     0.25200            0.19375    0.32150   \n",
       "3       942460471  0.13375  0.14700     0.50700            0.46175    0.14875   \n",
       "4      1004723013  0.15475  0.15575     0.28925            0.19800    0.16350   \n",
       "\n",
       "   ...  Fantasy  Film-Noir  Animation  Comedy  Children  Musical  Western  \\\n",
       "0  ...        1          0          1       1         1        0        0   \n",
       "1  ...        1          0          0       0         1        0        0   \n",
       "2  ...        0          0          0       1         0        0        0   \n",
       "3  ...        0          0          0       1         0        0        0   \n",
       "4  ...        0          0          0       1         0        0        0   \n",
       "\n",
       "   Adventure  Crime  Mystery  \n",
       "0          1      0        0  \n",
       "1          1      0        0  \n",
       "2          0      0        0  \n",
       "3          0      0        0  \n",
       "4          0      0        0  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one hot encoding for genres\n",
    "categories = set()\n",
    "for s in df['genres'].str.split('|').values:\n",
    "    if s != ['(no genres listed)']:\n",
    "        categories = categories.union(set(s))\n",
    "\n",
    "print(categories)\n",
    "\n",
    "# add columns for each category\n",
    "for category in categories:\n",
    "    df[category] = df['genres'].str.contains(category).astype(int)\n",
    "\n",
    "# delete genres column\n",
    "df = df.drop(columns=['genres'])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Duplicates Filtering\n",
    "The following results show that there are no duplicates in the dataset (as expected after merge operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  13816\n",
      "Number of rows after dropping duplicated rows:  13816\n"
     ]
    }
   ],
   "source": [
    "# print number of rows\n",
    "print('Number of rows: ', df.shape[0])\n",
    "\n",
    "# drop duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# print number of rows after dropping missing values\n",
    "print('Number of rows after dropping duplicated rows: ', df.shape[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # rating distribution from ratings.csv\\nsns.countplot(x='rating', data=ratings)\\nplt.show()\\n\\nsns.boxplot(x='rating', data=ratings)\\nplt.show() \""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # rating distribution from ratings.csv\n",
    "sns.countplot(x='rating', data=ratings)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x='rating', data=ratings)\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using discrete bins, a KDE plot smooths the observations with a Gaussian kernel, producing a continuous density estimate. This is used for continuous attributes like rating mean.\n",
    "\n",
    "It is done to show differences after data aggregation in calculating mean for each film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # rating distribution from df\\nsns.kdeplot(df['mean_rating'])\\nplt.xlabel('rating mean for film')\\nplt.title('Rating distribution in dataframe')\\nplt.show() \""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # rating distribution from df\n",
    "sns.kdeplot(df['mean_rating'])\n",
    "plt.xlabel('rating mean for film')\n",
    "plt.title('Rating distribution in dataframe')\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' movies_to_show = 5\\nfig, axs = plt.subplots(movies_to_show, sharex=True, sharey=True, figsize=(10, 10))\\n\\nmost_rated_movies = ratings.groupby(\\'movieId\\').count().sort_values(\\'rating\\', ascending=False).head(movies_to_show).index\\n\\nto_line_plot = []\\nfor i in range(movies_to_show):\\n    tmp = ratings.where(ratings[\\'movieId\\'] == most_rated_movies[i]).dropna()\\n    tmp[\\'date\\'] = pd.to_datetime(tmp[\\'timestamp\\'], unit=\\'s\\')\\n    \\n    # Computing the mean for each month\\n    tmp = tmp.resample(\"M\", on=\\'date\\').mean()[[\\'movieId\\', \\'rating\\']].dropna()\\n    to_line_plot.append(tmp)\\n    movie_title = movies.where(movies[\\'movieId\\'] == most_rated_movies[i]).dropna()[\\'title\\'].values[0]\\n    axs[i].set_title(\"Movie: \\'\" + movie_title + \"\\'\")\\n    \\n\\nfor i in range(movies_to_show):\\n    sns.lineplot(x=\\'date\\', y=\\'rating\\', ax=axs[i], data=to_line_plot[i])\\n\\nfig.suptitle(\\'Rating evolution for the 5 most rated movies\\')\\nplt.show() '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" movies_to_show = 5\n",
    "fig, axs = plt.subplots(movies_to_show, sharex=True, sharey=True, figsize=(10, 10))\n",
    "\n",
    "most_rated_movies = ratings.groupby('movieId').count().sort_values('rating', ascending=False).head(movies_to_show).index\n",
    "\n",
    "to_line_plot = []\n",
    "for i in range(movies_to_show):\n",
    "    tmp = ratings.where(ratings['movieId'] == most_rated_movies[i]).dropna()\n",
    "    tmp['date'] = pd.to_datetime(tmp['timestamp'], unit='s')\n",
    "    \n",
    "    # Computing the mean for each month\n",
    "    tmp = tmp.resample(\"M\", on='date').mean()[['movieId', 'rating']].dropna()\n",
    "    to_line_plot.append(tmp)\n",
    "    movie_title = movies.where(movies['movieId'] == most_rated_movies[i]).dropna()['title'].values[0]\n",
    "    axs[i].set_title(\"Movie: '\" + movie_title + \"'\")\n",
    "    \n",
    "\n",
    "for i in range(movies_to_show):\n",
    "    sns.lineplot(x='date', y='rating', ax=axs[i], data=to_line_plot[i])\n",
    "\n",
    "fig.suptitle('Rating evolution for the 5 most rated movies')\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Same as above cell but the 3 movies with the highest standard deviation\\nmovies_to_show = 3\\nfig, axs = plt.subplots(movies_to_show, sharex=True, sharey=True, figsize=(10, 10))\\n\\n# Take movies with at least 1000 ratings\\nhigh_std_movies = ratings.where(\\n    ratings[\\'movieId\\']\\n    .isin(ratings.groupby(\\'movieId\\')\\n          .count()\\n          .where(ratings.groupby(\\'movieId\\').count()[\\'rating\\'] > 1000)\\n          .dropna().index)\\n    ).dropna()\\n\\n# most_rated_movies = ratings.groupby(\\'movieId\\').count().sort_values(\\'rating\\', ascending=False).head(movies_to_show).index\\nhigh_std_movies = high_std_movies.groupby(\\'movieId\\').std().sort_values(\\'rating\\', ascending=False).head(movies_to_show).index\\n\\nto_line_plot = []\\nfor i in range(movies_to_show):\\n    tmp = ratings.where(ratings[\\'movieId\\'] == high_std_movies[i]).dropna()\\n    tmp[\\'date\\'] = pd.to_datetime(tmp[\\'timestamp\\'], unit=\\'s\\')\\n    \\n    # Computing the mean for each month\\n    tmp = tmp.resample(\"M\", on=\\'date\\').mean()[[\\'movieId\\', \\'rating\\']].dropna()\\n    to_line_plot.append(tmp)\\n    movie_title = movies.where(movies[\\'movieId\\'] == high_std_movies[i]).dropna()[\\'title\\'].values[0]\\n    axs[i].set_title(\"Movie: \\'\" + movie_title + \"\\'\")\\n\\nfor i in range(movies_to_show):\\n    sns.lineplot(x=\\'date\\', y=\\'rating\\', ax=axs[i], data=to_line_plot[i])\\n\\n# Print the titles of the movies\\nplt.show() '"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Same as above cell but the 3 movies with the highest standard deviation\n",
    "movies_to_show = 3\n",
    "fig, axs = plt.subplots(movies_to_show, sharex=True, sharey=True, figsize=(10, 10))\n",
    "\n",
    "# Take movies with at least 1000 ratings\n",
    "high_std_movies = ratings.where(\n",
    "    ratings['movieId']\n",
    "    .isin(ratings.groupby('movieId')\n",
    "          .count()\n",
    "          .where(ratings.groupby('movieId').count()['rating'] > 1000)\n",
    "          .dropna().index)\n",
    "    ).dropna()\n",
    "\n",
    "# most_rated_movies = ratings.groupby('movieId').count().sort_values('rating', ascending=False).head(movies_to_show).index\n",
    "high_std_movies = high_std_movies.groupby('movieId').std().sort_values('rating', ascending=False).head(movies_to_show).index\n",
    "\n",
    "to_line_plot = []\n",
    "for i in range(movies_to_show):\n",
    "    tmp = ratings.where(ratings['movieId'] == high_std_movies[i]).dropna()\n",
    "    tmp['date'] = pd.to_datetime(tmp['timestamp'], unit='s')\n",
    "    \n",
    "    # Computing the mean for each month\n",
    "    tmp = tmp.resample(\"M\", on='date').mean()[['movieId', 'rating']].dropna()\n",
    "    to_line_plot.append(tmp)\n",
    "    movie_title = movies.where(movies['movieId'] == high_std_movies[i]).dropna()['title'].values[0]\n",
    "    axs[i].set_title(\"Movie: '\" + movie_title + \"'\")\n",
    "\n",
    "for i in range(movies_to_show):\n",
    "    sns.lineplot(x='date', y='rating', ax=axs[i], data=to_line_plot[i])\n",
    "\n",
    "# Print the titles of the movies\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot density for every attribute of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # print distribution for ratings\\nfig, axs = plt.subplots(1, 2, figsize=(10, 2))\\nsns.kdeplot(df['mean_timestamp'], ax=axs[0], color='r', label='timestamp')\\nsns.kdeplot(df['rating_count'], ax=axs[1], color='b', label='rating')\\n\\naxs[0].set_xlabel('')\\naxs[0].set_ylabel('')\\naxs[0].title.set_text('Timestamp mean distribution')\\naxs[1].set_xlabel('')\\naxs[1].set_ylabel('')\\naxs[1].title.set_text('Rating count distribution')\\nplt.show() \""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # print distribution for ratings\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 2))\n",
    "sns.kdeplot(df['mean_timestamp'], ax=axs[0], color='r', label='timestamp')\n",
    "sns.kdeplot(df['rating_count'], ax=axs[1], color='b', label='rating')\n",
    "\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_ylabel('')\n",
    "axs[0].title.set_text('Timestamp mean distribution')\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].set_ylabel('')\n",
    "axs[1].title.set_text('Rating count distribution')\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # density plot for rating_count\\nfig, axs = plt.subplots(1,2, figsize=(10, 5))\\nsns.kdeplot(df['rating_count'], ax=axs[0], label='rating_count')\\nsns.kdeplot(df['rating_count'].where(df['rating_count'] < 50), ax=axs[1], label='rating_count < 50')\\n\\nprint('Number of movies with rating_count < 50: ', df.where(df['rating_count'] < 50).count()[0])\\nprint('Number of all movies: ', df.shape[0]) \""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # density plot for rating_count\n",
    "fig, axs = plt.subplots(1,2, figsize=(10, 5))\n",
    "sns.kdeplot(df['rating_count'], ax=axs[0], label='rating_count')\n",
    "sns.kdeplot(df['rating_count'].where(df['rating_count'] < 50), ax=axs[1], label='rating_count < 50')\n",
    "\n",
    "print('Number of movies with rating_count < 50: ', df.where(df['rating_count'] < 50).count()[0])\n",
    "print('Number of all movies: ', df.shape[0]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # plot for categories\\ncat = list(categories)\\n\\n# count the number of rows containing 1 for each category\\ncat_dict = {}\\nfor category in cat:\\n    cat_dict[category] = df[category].sum()\\n\\n# order the dictionary by value in descending order\\ncat_dict = {k: v for k, v in sorted(cat_dict.items(), key=lambda item: item[1], reverse=True)}\\n\\n# plot an histogram of the number of rows for each category\\nfig, axs = plt.subplots(1, 1, figsize=(20, 10))\\nax = sns.barplot(x=list(cat_dict.keys()), y=list(cat_dict.values()))\\nax.bar_label(container=ax.containers[0], labels=list(cat_dict.keys()))\\nplt.xticks([])\\nplt.show() '"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # plot for categories\n",
    "cat = list(categories)\n",
    "\n",
    "# count the number of rows containing 1 for each category\n",
    "cat_dict = {}\n",
    "for category in cat:\n",
    "    cat_dict[category] = df[category].sum()\n",
    "\n",
    "# order the dictionary by value in descending order\n",
    "cat_dict = {k: v for k, v in sorted(cat_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# plot an histogram of the number of rows for each category\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 10))\n",
    "ax = sns.barplot(x=list(cat_dict.keys()), y=list(cat_dict.values()))\n",
    "ax.bar_label(container=ax.containers[0], labels=list(cat_dict.keys()))\n",
    "plt.xticks([])\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # plot for tags\\n\\ntag_columns = list(df.columns)\\ntag_columns = df.drop(columns=['movieId','title','mean_rating','rating_count', 'mean_timestamp']).columns\\ntag_columns = [tag for tag in tag_columns if tag not in categories]\\n\\ntag_dict = {}\\nfor tag in tag_columns:\\n    tag_dict[tag] = df[tag].mean()\\n\\n# order the dictionary by value in descending order\\ntag_dict = {k: v for k, v in sorted(tag_dict.items(), key=lambda item: item[1], reverse=True)}\\n\\ndisplay('Tag mean: ', tag_dict)\\n\\n# plot tag mean\\nfig, axs = plt.subplots(1, 1, figsize=(20, 10))\\nax = sns.barplot(x=list(tag_dict.keys()), y=list(tag_dict.values()))\\nax.bar_label(container=ax.containers[0], labels=list(tag_dict.keys()))\\nplt.xticks([])\\nplt.show() \""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # plot for tags\n",
    "\n",
    "tag_columns = list(df.columns)\n",
    "tag_columns = df.drop(columns=['movieId','title','mean_rating','rating_count', 'mean_timestamp']).columns\n",
    "tag_columns = [tag for tag in tag_columns if tag not in categories]\n",
    "\n",
    "tag_dict = {}\n",
    "for tag in tag_columns:\n",
    "    tag_dict[tag] = df[tag].mean()\n",
    "\n",
    "# order the dictionary by value in descending order\n",
    "tag_dict = {k: v for k, v in sorted(tag_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "display('Tag mean: ', tag_dict)\n",
    "\n",
    "# plot tag mean\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20, 10))\n",
    "ax = sns.barplot(x=list(tag_dict.keys()), y=list(tag_dict.values()))\n",
    "ax.bar_label(container=ax.containers[0], labels=list(tag_dict.keys()))\n",
    "plt.xticks([])\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # count the number of rows containing 1 for Film-Noir and IMAX\\nprint('Number of Film-Noir movies: ', df['Film-Noir'].sum())\\nprint('Number of IMAX movies: ', df['IMAX'].sum()) \""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # count the number of rows containing 1 for Film-Noir and IMAX\n",
    "print('Number of Film-Noir movies: ', df['Film-Noir'].sum())\n",
    "print('Number of IMAX movies: ', df['IMAX'].sum()) \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_timestamp</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adapted from:book</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affectionate</th>\n",
       "      <th>allegory</th>\n",
       "      <th>...</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Children</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Western</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.893708</td>\n",
       "      <td>57309</td>\n",
       "      <td>1153152210</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.66250</td>\n",
       "      <td>0.31675</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>0.89375</td>\n",
       "      <td>0.67625</td>\n",
       "      <td>0.24600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.251527</td>\n",
       "      <td>24228</td>\n",
       "      <td>1122310117</td>\n",
       "      <td>0.15925</td>\n",
       "      <td>0.64025</td>\n",
       "      <td>0.51450</td>\n",
       "      <td>0.48450</td>\n",
       "      <td>0.97600</td>\n",
       "      <td>0.12675</td>\n",
       "      <td>0.17750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.142028</td>\n",
       "      <td>11804</td>\n",
       "      <td>980602256</td>\n",
       "      <td>0.11375</td>\n",
       "      <td>0.16025</td>\n",
       "      <td>0.25200</td>\n",
       "      <td>0.19375</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.09550</td>\n",
       "      <td>0.10775</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.853547</td>\n",
       "      <td>2523</td>\n",
       "      <td>942460471</td>\n",
       "      <td>0.13375</td>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.50700</td>\n",
       "      <td>0.46175</td>\n",
       "      <td>0.14875</td>\n",
       "      <td>0.13150</td>\n",
       "      <td>0.07750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.058434</td>\n",
       "      <td>11714</td>\n",
       "      <td>1004723013</td>\n",
       "      <td>0.15475</td>\n",
       "      <td>0.15575</td>\n",
       "      <td>0.28925</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.16350</td>\n",
       "      <td>0.11875</td>\n",
       "      <td>0.06975</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_rating  rating_count  mean_timestamp   absurd   action  adaptation  \\\n",
       "0     3.893708         57309      1153152210  0.10400  0.66250     0.31675   \n",
       "1     3.251527         24228      1122310117  0.15925  0.64025     0.51450   \n",
       "2     3.142028         11804       980602256  0.11375  0.16025     0.25200   \n",
       "3     2.853547          2523       942460471  0.13375  0.14700     0.50700   \n",
       "4     3.058434         11714      1004723013  0.15475  0.15575     0.28925   \n",
       "\n",
       "   adapted from:book  adventure  affectionate  allegory  ...  Film-Noir  \\\n",
       "0            0.28600    0.89375       0.67625   0.24600  ...          0   \n",
       "1            0.48450    0.97600       0.12675   0.17750  ...          0   \n",
       "2            0.19375    0.32150       0.09550   0.10775  ...          0   \n",
       "3            0.46175    0.14875       0.13150   0.07750  ...          0   \n",
       "4            0.19800    0.16350       0.11875   0.06975  ...          0   \n",
       "\n",
       "   Animation  Comedy  Children  Musical  Western  Adventure  Crime  Mystery  \\\n",
       "0          1       1         1        0        0          1      0        0   \n",
       "1          0       0         1        0        0          1      0        0   \n",
       "2          0       1         0        0        0          0      0        0   \n",
       "3          0       1         0        0        0          0      0        0   \n",
       "4          0       1         0        0        0          0      0        0   \n",
       "\n",
       "   year  \n",
       "0  1995  \n",
       "1  1995  \n",
       "2  1995  \n",
       "3  1995  \n",
       "4  1995  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from title extract year\n",
    "df['year'] = df['title'].str.extract('(\\(\\d{4}\\))', expand=True)\n",
    "# remove parentheses\n",
    "df['year'] = df['year'].str.extract('(\\d{4})', expand=True)\n",
    "\n",
    "# remove movies with no year\n",
    "df = df.dropna(subset=['year'])\n",
    "\n",
    "# convert year to int\n",
    "df['year'] = df['year'].astype(int)\n",
    "\n",
    "# delete title and movieId columns\n",
    "df = df.drop(columns=['movieId', 'title'])\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # density plot for film year\\nsns.kdeplot(df['year'])\\nplt.show() \""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # density plot for film year\n",
    "sns.kdeplot(df['year'])\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Compute the number of unique values for each column\\nunique_values = {}\\nfor column in df.columns:\\n    if column == 'mean_rating' or column == 'mean_timestamp' or column == 'year':\\n        unique_values[column] = np.unique(df[column], return_counts=True)\\n\\n# Print the number of unique values for each column\\nfor column in unique_values:\\n    print(column, ':', unique_values[column])\\n\\n# Plot the number of unique values for each column\\nfig, axs = plt.subplots(nrows=3, ncols=1, figsize=(7, 10))\\nsns.lineplot(x=unique_values['mean_rating'][0], y=unique_values['mean_rating'][1], ax=axs[0])\\naxs[0].set_xlabel('mean rating')\\naxs[0].set_ylabel('number of unique values')\\nsns.lineplot(x=unique_values['mean_timestamp'][0], y=unique_values['mean_timestamp'][1], ax=axs[1])\\naxs[1].set_xlabel('mean timestamp')\\naxs[1].set_ylabel('number of unique values')\\nsns.lineplot(x=unique_values['year'][0], y=unique_values['year'][1], ax=axs[2])\\naxs[2].set_xlabel('year')\\naxs[2].set_ylabel('number of unique values')\\nplt.show() \""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Compute the number of unique values for each column\n",
    "unique_values = {}\n",
    "for column in df.columns:\n",
    "    if column == 'mean_rating' or column == 'mean_timestamp' or column == 'year':\n",
    "        unique_values[column] = np.unique(df[column], return_counts=True)\n",
    "\n",
    "# Print the number of unique values for each column\n",
    "for column in unique_values:\n",
    "    print(column, ':', unique_values[column])\n",
    "\n",
    "# Plot the number of unique values for each column\n",
    "fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(7, 10))\n",
    "sns.lineplot(x=unique_values['mean_rating'][0], y=unique_values['mean_rating'][1], ax=axs[0])\n",
    "axs[0].set_xlabel('mean rating')\n",
    "axs[0].set_ylabel('number of unique values')\n",
    "sns.lineplot(x=unique_values['mean_timestamp'][0], y=unique_values['mean_timestamp'][1], ax=axs[1])\n",
    "axs[1].set_xlabel('mean timestamp')\n",
    "axs[1].set_ylabel('number of unique values')\n",
    "sns.lineplot(x=unique_values['year'][0], y=unique_values['year'][1], ax=axs[2])\n",
    "axs[2].set_xlabel('year')\n",
    "axs[2].set_ylabel('number of unique values')\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # show year and year_timestamp in the same plot with values from 2000 to 2020\\ndf_year = df.copy()\\ndf_year['mean_timestamp'] = pd.to_datetime(df['mean_timestamp'], unit='s')\\ndf_year['year_timestamp'] = df_year['mean_timestamp'].dt.year\\n\\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\\nsns.kdeplot(df_year['year_timestamp'], ax=axs[0], label='timestamp year')\\nsns.kdeplot(df_year['year'], ax=axs[0], label='film year')\\naxs[0].set_xlabel('year')\\nsns.kdeplot(df_year['year_timestamp'], ax=axs[1], label='timestamp year')\\nsns.kdeplot(df_year['year'], ax=axs[1], label='film year')\\naxs[1].set_xlabel('year')\\naxs[1].set_xlim(2000, 2020)\\naxs[1].set_xticks(np.arange(2000, 2022, 4))\\nplt.show() \""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # show year and year_timestamp in the same plot with values from 2000 to 2020\n",
    "df_year = df.copy()\n",
    "df_year['mean_timestamp'] = pd.to_datetime(df['mean_timestamp'], unit='s')\n",
    "df_year['year_timestamp'] = df_year['mean_timestamp'].dt.year\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "sns.kdeplot(df_year['year_timestamp'], ax=axs[0], label='timestamp year')\n",
    "sns.kdeplot(df_year['year'], ax=axs[0], label='film year')\n",
    "axs[0].set_xlabel('year')\n",
    "sns.kdeplot(df_year['year_timestamp'], ax=axs[1], label='timestamp year')\n",
    "sns.kdeplot(df_year['year'], ax=axs[1], label='film year')\n",
    "axs[1].set_xlabel('year')\n",
    "axs[1].set_xlim(2000, 2020)\n",
    "axs[1].set_xticks(np.arange(2000, 2022, 4))\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_timestamp</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adapted from:book</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affectionate</th>\n",
       "      <th>allegory</th>\n",
       "      <th>...</th>\n",
       "      <th>visually stunning</th>\n",
       "      <th>weapons</th>\n",
       "      <th>weird</th>\n",
       "      <th>whimsical</th>\n",
       "      <th>witty</th>\n",
       "      <th>women</th>\n",
       "      <th>writers</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.893708</td>\n",
       "      <td>57309</td>\n",
       "      <td>1153152210</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.66250</td>\n",
       "      <td>0.31675</td>\n",
       "      <td>0.28600</td>\n",
       "      <td>0.89375</td>\n",
       "      <td>0.67625</td>\n",
       "      <td>0.24600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67325</td>\n",
       "      <td>0.26375</td>\n",
       "      <td>0.42700</td>\n",
       "      <td>0.58700</td>\n",
       "      <td>0.69400</td>\n",
       "      <td>0.08925</td>\n",
       "      <td>0.14125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.251527</td>\n",
       "      <td>24228</td>\n",
       "      <td>1122310117</td>\n",
       "      <td>0.15925</td>\n",
       "      <td>0.64025</td>\n",
       "      <td>0.51450</td>\n",
       "      <td>0.48450</td>\n",
       "      <td>0.97600</td>\n",
       "      <td>0.12675</td>\n",
       "      <td>0.17750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21700</td>\n",
       "      <td>0.17800</td>\n",
       "      <td>0.38650</td>\n",
       "      <td>0.29250</td>\n",
       "      <td>0.18725</td>\n",
       "      <td>0.13525</td>\n",
       "      <td>0.12225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.142028</td>\n",
       "      <td>11804</td>\n",
       "      <td>980602256</td>\n",
       "      <td>0.11375</td>\n",
       "      <td>0.16025</td>\n",
       "      <td>0.25200</td>\n",
       "      <td>0.19375</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>0.09550</td>\n",
       "      <td>0.10775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09850</td>\n",
       "      <td>0.14125</td>\n",
       "      <td>0.24350</td>\n",
       "      <td>0.13025</td>\n",
       "      <td>0.22325</td>\n",
       "      <td>0.35075</td>\n",
       "      <td>0.12200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.853547</td>\n",
       "      <td>2523</td>\n",
       "      <td>942460471</td>\n",
       "      <td>0.13375</td>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.50700</td>\n",
       "      <td>0.46175</td>\n",
       "      <td>0.14875</td>\n",
       "      <td>0.13150</td>\n",
       "      <td>0.07750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11625</td>\n",
       "      <td>0.28950</td>\n",
       "      <td>0.21975</td>\n",
       "      <td>0.14775</td>\n",
       "      <td>0.10725</td>\n",
       "      <td>0.97525</td>\n",
       "      <td>0.18200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.058434</td>\n",
       "      <td>11714</td>\n",
       "      <td>1004723013</td>\n",
       "      <td>0.15475</td>\n",
       "      <td>0.15575</td>\n",
       "      <td>0.28925</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.16350</td>\n",
       "      <td>0.11875</td>\n",
       "      <td>0.06975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11875</td>\n",
       "      <td>0.12025</td>\n",
       "      <td>0.29350</td>\n",
       "      <td>0.16425</td>\n",
       "      <td>0.10475</td>\n",
       "      <td>0.40225</td>\n",
       "      <td>0.19225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_rating  rating_count  mean_timestamp   absurd   action  adaptation  \\\n",
       "0     3.893708         57309      1153152210  0.10400  0.66250     0.31675   \n",
       "1     3.251527         24228      1122310117  0.15925  0.64025     0.51450   \n",
       "2     3.142028         11804       980602256  0.11375  0.16025     0.25200   \n",
       "3     2.853547          2523       942460471  0.13375  0.14700     0.50700   \n",
       "4     3.058434         11714      1004723013  0.15475  0.15575     0.28925   \n",
       "\n",
       "   adapted from:book  adventure  affectionate  allegory  ...  \\\n",
       "0            0.28600    0.89375       0.67625   0.24600  ...   \n",
       "1            0.48450    0.97600       0.12675   0.17750  ...   \n",
       "2            0.19375    0.32150       0.09550   0.10775  ...   \n",
       "3            0.46175    0.14875       0.13150   0.07750  ...   \n",
       "4            0.19800    0.16350       0.11875   0.06975  ...   \n",
       "\n",
       "   visually stunning  weapons    weird  whimsical    witty    women  writers  \\\n",
       "0            0.67325  0.26375  0.42700    0.58700  0.69400  0.08925  0.14125   \n",
       "1            0.21700  0.17800  0.38650    0.29250  0.18725  0.13525  0.12225   \n",
       "2            0.09850  0.14125  0.24350    0.13025  0.22325  0.35075  0.12200   \n",
       "3            0.11625  0.28950  0.21975    0.14775  0.10725  0.97525  0.18200   \n",
       "4            0.11875  0.12025  0.29350    0.16425  0.10475  0.40225  0.19225   \n",
       "\n",
       "   IMAX  Film-Noir  year  \n",
       "0     0          0  1995  \n",
       "1     0          0  1995  \n",
       "2     0          0  1995  \n",
       "3     0          0  1995  \n",
       "4     0          0  1995  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop columns that are in cat but not in lower_case_tags\n",
    "lower_case_tags = [str.lower(t) for t in genome_tags['tag'].values]\n",
    "cat = list(categories)\n",
    "for c in cat:\n",
    "    if c.lower() in lower_case_tags:\n",
    "        df = df.drop(columns=[c])\n",
    "        # print('Dropped column', c)\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # TODO - balancing dataset only for training set\\n# remove samples_to_drop movies with mean_rating between 2.5 and 4\\nsamples_to_drop = 25000\\ndf_preprocessed = df.copy()\\ndf_preprocessed = df_preprocessed.drop(df_preprocessed[(df_preprocessed['mean_rating'] >= 2.5) & (df_preprocessed['mean_rating'] <= 4)].sample(samples_to_drop).index)\\n\\n# rating distribution from df\\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\\nsns.kdeplot(df['mean_rating'], ax=axs[0])\\nsns.kdeplot(df_preprocessed['mean_rating'], ax=axs[1])\\nplt.xlabel('rating mean for film')\\nplt.title('Rating distribution in dataframe')\\nplt.show()\\n\\n# number of samples in df and df_preprocessed\\nprint('Number of samples in df: ', df.shape[0])\\nprint('Number of samples in df_preprocessed: ', df_preprocessed.shape[0]) \""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # TODO - balancing dataset only for training set\n",
    "# remove samples_to_drop movies with mean_rating between 2.5 and 4\n",
    "samples_to_drop = 25000\n",
    "df_preprocessed = df.copy()\n",
    "df_preprocessed = df_preprocessed.drop(df_preprocessed[(df_preprocessed['mean_rating'] >= 2.5) & (df_preprocessed['mean_rating'] <= 4)].sample(samples_to_drop).index)\n",
    "\n",
    "# rating distribution from df\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.kdeplot(df['mean_rating'], ax=axs[0])\n",
    "sns.kdeplot(df_preprocessed['mean_rating'], ax=axs[1])\n",
    "plt.xlabel('rating mean for film')\n",
    "plt.title('Rating distribution in dataframe')\n",
    "plt.show()\n",
    "\n",
    "# number of samples in df and df_preprocessed\n",
    "print('Number of samples in df: ', df.shape[0])\n",
    "print('Number of samples in df_preprocessed: ', df_preprocessed.shape[0]) \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # TODO - fit the model to raw, scaled and standardized data and compare the performance for best results\\n\\nmean_rating_column = df['mean_rating']\\n\\nscaler = MinMaxScaler()\\nnormalized_data = scaler.fit_transform(df.drop(columns=['mean_rating']))\\n\\n# show normalized data\\ndf = pd.DataFrame(normalized_data, columns=df.columns[:-1])\\ndf['mean_rating'] = mean_rating_column\\ndf = df.dropna()\\nmean_rating_column = df['mean_rating']\\ndisplay(df.shape)\\n \""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # TODO - fit the model to raw, scaled and standardized data and compare the performance for best results\n",
    "\n",
    "mean_rating_column = df['mean_rating']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df.drop(columns=['mean_rating']))\n",
    "\n",
    "# show normalized data\n",
    "df = pd.DataFrame(normalized_data, columns=df.columns[:-1])\n",
    "df['mean_rating'] = mean_rating_column\n",
    "df = df.dropna()\n",
    "mean_rating_column = df['mean_rating']\n",
    "display(df.shape)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_timestamp</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adapted from:book</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affectionate</th>\n",
       "      <th>allegory</th>\n",
       "      <th>art</th>\n",
       "      <th>...</th>\n",
       "      <th>weapons</th>\n",
       "      <th>weird</th>\n",
       "      <th>whimsical</th>\n",
       "      <th>witty</th>\n",
       "      <th>women</th>\n",
       "      <th>writers</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>year</th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703135</td>\n",
       "      <td>0.407213</td>\n",
       "      <td>0.077959</td>\n",
       "      <td>0.659114</td>\n",
       "      <td>0.266008</td>\n",
       "      <td>0.246281</td>\n",
       "      <td>0.894423</td>\n",
       "      <td>0.692328</td>\n",
       "      <td>0.227026</td>\n",
       "      <td>0.179024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232614</td>\n",
       "      <td>0.399206</td>\n",
       "      <td>0.602350</td>\n",
       "      <td>0.745690</td>\n",
       "      <td>0.063775</td>\n",
       "      <td>0.108818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>3.893708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.297024</td>\n",
       "      <td>0.363590</td>\n",
       "      <td>0.135198</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.489140</td>\n",
       "      <td>0.457226</td>\n",
       "      <td>0.979767</td>\n",
       "      <td>0.110847</td>\n",
       "      <td>0.156096</td>\n",
       "      <td>0.125549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141220</td>\n",
       "      <td>0.356349</td>\n",
       "      <td>0.280404</td>\n",
       "      <td>0.163218</td>\n",
       "      <td>0.111283</td>\n",
       "      <td>0.088448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>3.251527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144504</td>\n",
       "      <td>0.163159</td>\n",
       "      <td>0.088060</td>\n",
       "      <td>0.141864</td>\n",
       "      <td>0.192948</td>\n",
       "      <td>0.148247</td>\n",
       "      <td>0.300649</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.083873</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102052</td>\n",
       "      <td>0.205026</td>\n",
       "      <td>0.103034</td>\n",
       "      <td>0.204598</td>\n",
       "      <td>0.333850</td>\n",
       "      <td>0.088180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>3.142028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030568</td>\n",
       "      <td>0.109211</td>\n",
       "      <td>0.108780</td>\n",
       "      <td>0.128218</td>\n",
       "      <td>0.480677</td>\n",
       "      <td>0.433050</td>\n",
       "      <td>0.121401</td>\n",
       "      <td>0.115873</td>\n",
       "      <td>0.052550</td>\n",
       "      <td>0.149574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260059</td>\n",
       "      <td>0.179894</td>\n",
       "      <td>0.122165</td>\n",
       "      <td>0.071264</td>\n",
       "      <td>0.978828</td>\n",
       "      <td>0.152506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>2.853547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143399</td>\n",
       "      <td>0.197275</td>\n",
       "      <td>0.130536</td>\n",
       "      <td>0.137230</td>\n",
       "      <td>0.234979</td>\n",
       "      <td>0.152763</td>\n",
       "      <td>0.136706</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>0.071558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079670</td>\n",
       "      <td>0.257937</td>\n",
       "      <td>0.140202</td>\n",
       "      <td>0.068391</td>\n",
       "      <td>0.387038</td>\n",
       "      <td>0.163495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>3.058434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_count  mean_timestamp    absurd    action  adaptation  \\\n",
       "0      0.703135        0.407213  0.077959  0.659114    0.266008   \n",
       "1      0.297024        0.363590  0.135198  0.636200    0.489140   \n",
       "2      0.144504        0.163159  0.088060  0.141864    0.192948   \n",
       "3      0.030568        0.109211  0.108780  0.128218    0.480677   \n",
       "4      0.143399        0.197275  0.130536  0.137230    0.234979   \n",
       "\n",
       "   adapted from:book  adventure  affectionate  allegory       art  ...  \\\n",
       "0           0.246281   0.894423      0.692328  0.227026  0.179024  ...   \n",
       "1           0.457226   0.979767      0.110847  0.156096  0.125549  ...   \n",
       "2           0.148247   0.300649      0.077778  0.083873  0.069491  ...   \n",
       "3           0.433050   0.121401      0.115873  0.052550  0.149574  ...   \n",
       "4           0.152763   0.136706      0.102381  0.044525  0.071558  ...   \n",
       "\n",
       "    weapons     weird  whimsical     witty     women   writers  IMAX  \\\n",
       "0  0.232614  0.399206   0.602350  0.745690  0.063775  0.108818   0.0   \n",
       "1  0.141220  0.356349   0.280404  0.163218  0.111283  0.088448   0.0   \n",
       "2  0.102052  0.205026   0.103034  0.204598  0.333850  0.088180   0.0   \n",
       "3  0.260059  0.179894   0.122165  0.071264  0.978828  0.152506   0.0   \n",
       "4  0.079670  0.257937   0.140202  0.068391  0.387038  0.163495   0.0   \n",
       "\n",
       "   Film-Noir      year  mean_rating  \n",
       "0        0.0  0.804878     3.893708  \n",
       "1        0.0  0.804878     3.251527  \n",
       "2        0.0  0.804878     3.142028  \n",
       "3        0.0  0.804878     2.853547  \n",
       "4        0.0  0.804878     3.058434  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize columns\n",
    "df = df.dropna()\n",
    "mean_rating_column = df['mean_rating']\n",
    "df = df.drop(columns=['mean_rating'])\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "df['mean_rating'] = mean_rating_column\n",
    "display(df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation results\n",
    "This correlation table shows the relationship between different movie genres and several movie characteristics such as mean rating, rating count, and year of release. The values in the table represent the Pearson correlation coefficient, which ranges from -1 to 1 and measures the linear association between two variables. Positive values indicate a positive association, meaning that as one variable increases, the other variable also increases. Negative values indicate a negative association, meaning that as one variable increases, the other variable decreases.\n",
    "\n",
    "<!-- Some observations from the table:\n",
    "\n",
    "There is a positive correlation between the mean rating and rating count of a movie (0.13). This indicates that movies with higher ratings tend to have more ratings.\n",
    "Film-Noir has a moderate positive correlation with Crime (0.15) and Mystery (0.06). This suggests that movies classified as Film-Noir often have elements of crime and mystery.\n",
    "Horror movies have a negative correlation with mean rating (-0.22), indicating that they tend to have lower ratings.\n",
    "Drama movies have a moderate positive correlation with mean rating (0.15) and a moderate positive correlation with Thriller movies (0.24).\n",
    "There is a negative correlation between year of release and rating count (-0.27), which suggests that older movies tend to have fewer ratings.\n",
    "In conclusion, this table provides useful information about the relationship between different movie genres and movie characteristics, and can be used to make informed decisions about movie selection and production. -->\n",
    "\n",
    "### Covariance results\n",
    "Covariance is a measure of the linear relationship between two variables. It measures how changes in one variable are associated with changes in the other variable. Covariance is expressed as a numerical value and can range from negative to positive values. A positive covariance means that the two variables are positively related, while a negative covariance means that they are inversely related. A covariance of zero means that there is no linear relationship between the variables (i.e. variables are indipendent).\n",
    "\n",
    "<!-- In the table provided, the covariance between two variables can be found in the entries of the matrix. For example, the covariance between \"mean_rating\" and \"Film-Noir\" is 0.001774, indicating a very small positive relationship between the two variables. The covariance between \"rating_count\" and \"Crime\" is 43.331685, indicating a stronger positive relationship between these two variables.\n",
    "\n",
    "It's important to keep in mind that covariance only measures linear relationships, so it may not be able to fully capture more complex relationships between variables.\n",
    "\n",
    "As it's possible to see in the table, variables tend to be indipendent from each others, this is not valid only for two variables: rating_count and mean_timestamp. These two attributes are highly dipendent with all other attributes. -->\n",
    "\n",
    "### Dataset Describe\n",
    "The describe() function applied on the Pandas DataFrame provides statistical information about the features in the DataFrame. According to the results, the mean rating for the movies is 3.110263, with a standard deviation of 0.653225. The minimum and maximum ratings are 0.5 and 5, respectively. The mean count of ratings for each movie is 596.81, with a standard deviation of 2929.96.\n",
    "\n",
    "<!-- The genre columns (Film-Noir, Crime, Mystery, Animation, etc.) are binary, with a mean of either 0 or 0.01 to 0.28. The 25th, 50th, and 75th percentiles for these features are either 0 or close to 0, indicating that the majority of the movies belong to a particular genre. The year_timestamp feature has a mean of 2014.22, with a standard deviation of 4.7. The year feature has a mean of 1991.57 and a standard deviation of 25.09. -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # compute analysis for \\'mean_rating\\', \\'rating_count\\', \\'mean_timestamp\\', \\'Film-Noir\\', \\'IMAX\\'\\ncorr = df[[\\'mean_rating\\', \\'rating_count\\', \\'mean_timestamp\\', \\'Film-Noir\\', \\'IMAX\\']].corr()\\nprint(corr)\\ncov = df[[\\'mean_rating\\', \\'rating_count\\', \\'mean_timestamp\\', \\'Film-Noir\\', \\'IMAX\\']].cov()\\nprint(cov)\\ndesc = df[[\\'mean_rating\\', \\'rating_count\\', \\'mean_timestamp\\', \\'Film-Noir\\', \\'IMAX\\']].describe()\\nprint(desc)\\n\\n# follow examples from slides on Data Visualization (pages 6-8)\\nfig, axs = plt.subplots(2, 1, figsize=(10, 10))\\n# show results of correlation in a graphic way\\n# Plot the heatmap of the correlation matrix\\nsns.heatmap(corr, annot=True, cmap=\"YlGnBu\", ax=axs[0])\\n# show results of covariance in a graphic way\\n# Plot the heatmap of the covariance matrix\\nsns.heatmap(cov, annot=True, cmap=\"YlGnBu\", ax=axs[1], vmax=1, vmin=-1)\\n\\nplt.show()\\n\\n# Plot the table\\nplt.figure(figsize=(10, 5))\\nsns.heatmap(desc, annot=True, cmap=\\'Reds\\', vmax=1, vmin=0)\\nplt.show() '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # compute analysis for 'mean_rating', 'rating_count', 'mean_timestamp', 'Film-Noir', 'IMAX'\n",
    "corr = df[['mean_rating', 'rating_count', 'mean_timestamp', 'Film-Noir', 'IMAX']].corr()\n",
    "print(corr)\n",
    "cov = df[['mean_rating', 'rating_count', 'mean_timestamp', 'Film-Noir', 'IMAX']].cov()\n",
    "print(cov)\n",
    "desc = df[['mean_rating', 'rating_count', 'mean_timestamp', 'Film-Noir', 'IMAX']].describe()\n",
    "print(desc)\n",
    "\n",
    "# follow examples from slides on Data Visualization (pages 6-8)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "# show results of correlation in a graphic way\n",
    "# Plot the heatmap of the correlation matrix\n",
    "sns.heatmap(corr, annot=True, cmap=\"YlGnBu\", ax=axs[0])\n",
    "# show results of covariance in a graphic way\n",
    "# Plot the heatmap of the covariance matrix\n",
    "sns.heatmap(cov, annot=True, cmap=\"YlGnBu\", ax=axs[1], vmax=1, vmin=-1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the table\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(desc, annot=True, cmap='Reds', vmax=1, vmin=0)\n",
    "plt.show() \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # compute analysis for other attributes\\ncorr = df.corr()\\ncov = df.cov()\\ndesc = df.describe()\\n\\n# Plot the heatmap of the correlation matrix\\nplt.figure(figsize=(50, 50))\\nsns.heatmap(corr, cmap=\"YlGnBu\")\\nplt.show()\\n\\n# Plot the heatmap of the covariance matrix\\nplt.figure(figsize=(50, 50))\\nsns.heatmap(cov, cmap=\"YlGnBu\", vmax=1, vmin=-1)\\nplt.show()\\n\\n# Plot the table\\nplt.figure(figsize=(50, 50))\\nsns.heatmap(desc, cmap=\\'Reds\\', vmax=1, vmin=0)\\nplt.show() '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # compute analysis for other attributes\n",
    "corr = df.corr()\n",
    "cov = df.cov()\n",
    "desc = df.describe()\n",
    "\n",
    "# Plot the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(50, 50))\n",
    "sns.heatmap(corr, cmap=\"YlGnBu\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the heatmap of the covariance matrix\n",
    "plt.figure(figsize=(50, 50))\n",
    "sns.heatmap(cov, cmap=\"YlGnBu\", vmax=1, vmin=-1)\n",
    "plt.show()\n",
    "\n",
    "# Plot the table\n",
    "plt.figure(figsize=(50, 50))\n",
    "sns.heatmap(desc, cmap='Reds', vmax=1, vmin=0)\n",
    "plt.show() \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as csv file\n",
    "df.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" df_PCA = df.copy()\\n\\nmean_rating_column = df_PCA['mean_rating']\\nX_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = train_test_split(df.drop(columns=['mean_rating']), mean_rating_column, test_size=0.1, random_state=42)\\nprint('X shape:',df.drop(columns=['mean_rating']).shape)\\nprint('y shape:',mean_rating_column.shape)\\nprint('X_train shape:',X_train_PCA.shape)\\nprint('y_train shape:',y_train_PCA.shape)\\nprint('X_test shape:',X_test_PCA.shape)\\nprint('y_test shape:',y_test_PCA.shape)\\n\\npca = decomposition.PCA()\\npca.fit(X_train_PCA)\\nprint('pca.mean_:', pca.mean_)\\nprint('pca.explained_variance_:', pca.explained_variance_)\\nprint('pca.explained_variance_ratio_:', pca.explained_variance_ratio_)\\nprint('pca.components_:', pca.components_)\\n\\nX_train_PCA = pca.transform(X_train_PCA)\\nplt.scatter(X_train_PCA[:, 0], X_train_PCA[:, 1], c=y_train_PCA)\\nplt.show()\\nX_test_PCA = pca.transform(X_test_PCA)\\nplt.scatter(X_test_PCA[:, 0], X_test_PCA[:, 1], c=y_test_PCA)\\nplt.show() \""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" df_PCA = df.copy()\n",
    "\n",
    "mean_rating_column = df_PCA['mean_rating']\n",
    "X_train_PCA, X_test_PCA, y_train_PCA, y_test_PCA = train_test_split(df.drop(columns=['mean_rating']), mean_rating_column, test_size=0.1, random_state=42)\n",
    "print('X shape:',df.drop(columns=['mean_rating']).shape)\n",
    "print('y shape:',mean_rating_column.shape)\n",
    "print('X_train shape:',X_train_PCA.shape)\n",
    "print('y_train shape:',y_train_PCA.shape)\n",
    "print('X_test shape:',X_test_PCA.shape)\n",
    "print('y_test shape:',y_test_PCA.shape)\n",
    "\n",
    "pca = decomposition.PCA()\n",
    "pca.fit(X_train_PCA)\n",
    "print('pca.mean_:', pca.mean_)\n",
    "print('pca.explained_variance_:', pca.explained_variance_)\n",
    "print('pca.explained_variance_ratio_:', pca.explained_variance_ratio_)\n",
    "print('pca.components_:', pca.components_)\n",
    "\n",
    "X_train_PCA = pca.transform(X_train_PCA)\n",
    "plt.scatter(X_train_PCA[:, 0], X_train_PCA[:, 1], c=y_train_PCA)\n",
    "plt.show()\n",
    "X_test_PCA = pca.transform(X_test_PCA)\n",
    "plt.scatter(X_test_PCA[:, 0], X_test_PCA[:, 1], c=y_test_PCA)\n",
    "plt.show() \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df.drop(columns=['mean_rating'])\n",
    "y = df['mean_rating']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.01\n",
      "Coefficient of determination: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Create Linear Regression model in sklearn\n",
    "\n",
    "# Create the model\n",
    "LR_model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = LR_model.predict(X_test)\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Create Stochastic Gradient Descent model in sklearn\\n\\n# Create the model\\nSGD_model = SGDRegressor()\\n\\n# Train the model on the training data\\nSGD_model.fit(X_train, y_train)\\n\\n# Evaluate the model on the test data\\ny_pred = SGD_model.predict(X_test)\\nprint('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\\nprint('Coefficient of determination: %.2f' % r2_score(y_test, y_pred)) \""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Create Stochastic Gradient Descent model in sklearn\n",
    "\n",
    "# Create the model\n",
    "SGD_model = SGDRegressor()\n",
    "\n",
    "# Train the model on the training data\n",
    "SGD_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = SGD_model.predict(X_test)\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred)) \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": [
     "no_run"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # Create SVM model in sklearn\\n\\n# Create the model\\nSVM_model = SVR()\\n\\n# Train the model on the training data\\nSVM_model.fit(X_train, y_train)\\n\\n# Evaluate the model on the test data\\ny_pred = SVM_model.predict(X_test)\\nprint('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\\nprint('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\\n\\ndisplay(y_test[:5])\\ndisplay(y_pred[:5]) \""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Create SVM model in sklearn\n",
    "\n",
    "# Create the model\n",
    "SVM_model = SVR()\n",
    "\n",
    "# Train the model on the training data\n",
    "SVM_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = SVM_model.predict(X_test)\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "display(y_test[:5])\n",
    "display(y_pred[:5]) \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" KNN_model = KNeighborsRegressor(n_neighbors=5)\\nKNN_model.fit(X_train, y_train)\\n\\n# Evaluate the model on the test data\\ny_pred = KNN_model.predict(X_test)\\nprint('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\\nprint('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\\n\\ndisplay(y_test[:5])\\ndisplay(y_pred[:5]) \""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" KNN_model = KNeighborsRegressor(n_neighbors=5)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = KNN_model.predict(X_test)\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "display(y_test[:5])\n",
    "display(y_pred[:5]) \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" DT_model = DecisionTreeRegressor()\\nDT_model.fit(X_train, y_train)\\n\\n# Evaluate the model on the test data\\ny_pred = DT_model.predict(X_test)\\nprint('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\\nprint('Coefficient of determination: %.2f' % r2_score(y_test, y_pred)) \""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" DT_model = DecisionTreeRegressor()\n",
    "DT_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "y_pred = DT_model.predict(X_test)\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred)) \"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the problem as classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "Recall: 0.35\n",
      "Precision: 0.47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' display(y_test_binned[:5])\\ndisplay(y_pred[:5]) '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bin y_train and y_test into 10 bins\n",
    "y_train_binned = pd.cut(y_train, 10, labels=False)\n",
    "y_test_binned = pd.cut(y_test, 10, labels=False)\n",
    "\n",
    "\"\"\" print('Binned values:', np.unique(y_train_binned))\n",
    "display(y_train_binned[:5]) \"\"\"\n",
    "\n",
    "# use the binned values to train the model\n",
    "\n",
    "RFC_classifier = RandomForestClassifier()\n",
    "RFC_classifier.fit(X_train, y_train_binned)\n",
    "\n",
    "y_pred = RFC_classifier.predict(X_test)\n",
    "\n",
    "# evaluation of y_pred\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test_binned, y_pred))\n",
    "print('Recall: %.2f' % recall_score(y_test_binned, y_pred, average='macro'))\n",
    "print('Precision: %.2f' % precision_score(y_test_binned, y_pred, average='macro'))\n",
    "\n",
    "\"\"\" display(y_test_binned[:5])\n",
    "display(y_pred[:5]) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import decomposition\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "#look for GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(\"Device: {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility -> il risultato tra un run e il successivo è lo stesso\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_random(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def test_model(model, criterion, loader):\\n    loss = 0\\n    y_pred = torch.tensor([]).to(device)\\n    y_true = torch.tensor([]).to(device)\\n    i = 0\\n\\n    for _, (x, y) in enumerate(loader):\\n        i += 1\\n        x = x.to(device)\\n        y = y.to(device)\\n        output = model(x)\\n        loss += criterion(output.squeeze(), y)\\n        y_pred = torch.cat((y_pred, output), 0)\\n        y_true = torch.cat((y_true, y), 0)\\n\\n    return loss /i, y_pred.squeeze(), y_true '"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training process\n",
    "def train_model(model, criterion, optimizer, epochs, data_loader, val_loader, device, writer):\n",
    "    n_iter = 0\n",
    "    patience = 10\n",
    "    best_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # per verificare che ci troviamo in training e non in validation per evitare che il modello aggiorni i pesi\n",
    "        for data, targets in data_loader:\n",
    "            # per spostare il minibatch in GPU\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            # Forward pass -> chiama la funzione forward\n",
    "            y_pred = model(data)\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred.squeeze(), targets)\n",
    "            # serve per azzerare il gradiente\n",
    "            optimizer.zero_grad()\n",
    "            # la barra separa Loss e la sezione train\n",
    "            writer.add_scalar(\"Loss/train\", loss, n_iter)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # aggiorna i pesi della rete\n",
    "            optimizer.step()\n",
    "            n_iter += 1\n",
    "\n",
    "        \n",
    "        # validation\n",
    "        loss_val, _, _ = test_model(model, criterion, val_loader, device)\n",
    "\n",
    "        # early stopping\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            best_model = copy.deepcopy(model)\n",
    "            patience = 10\n",
    "        else:\n",
    "            patience = patience - 1\n",
    "            if patience == 0:\n",
    "                print(\"\\nEarly stopping\")\n",
    "                return best_model\n",
    "\n",
    "        print(\"Epoch: [{}/{}], Patience: {}, Loss: {:.4f}, Val Loss: {:.4f}\".format(epoch+1, epochs, patience, loss, loss_val), end='\\r')\n",
    "        writer.add_scalar(\"Loss/val\", loss_val, epoch)\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "#evaluation process -> utilizzata sia per la validation che per il test\n",
    "def test_model(model, criterion, data_loader, device):\n",
    "    # model.eval() # per evitare che il modello aggiorni i pesi\n",
    "    loss = 0\n",
    "    y_pred = torch.tensor([]).to(device)\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    num_samples = 0\n",
    "    \n",
    "    for data, targets in data_loader:\n",
    "        num_samples += 1\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        output = model(data)\n",
    "        loss += criterion(output.squeeze(), targets)\n",
    "        y_pred = torch.cat((y_pred, output), 0)\n",
    "        y_true = torch.cat((y_true, targets), 0)\n",
    "\n",
    "    return loss/num_samples, y_pred.squeeze(), y_true\n",
    "\n",
    "\n",
    "\"\"\" def test_model(model, criterion, loader):\n",
    "    loss = 0\n",
    "    y_pred = torch.tensor([]).to(device)\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    i = 0\n",
    "\n",
    "    for _, (x, y) in enumerate(loader):\n",
    "        i += 1\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model(x)\n",
    "        loss += criterion(output.squeeze(), y)\n",
    "        y_pred = torch.cat((y_pred, output), 0)\n",
    "        y_true = torch.cat((y_true, y), 0)\n",
    "\n",
    "    return loss /i, y_pred.squeeze(), y_true \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class NN(nn.Module):\\n    def __init__(self, input_size, hidden_sizes, dropout_prob=0):\\n        super(NN, self).__init__()\\n        self.input_size = input_size\\n        self.hidden_sizes = hidden_sizes\\n        self.dp = dropout_prob\\n        \\n        model = [\\n            nn.Linear(self.input_size, self.hidden_sizes[0]),\\n            nn.ReLU(),\\n            nn.Dropout(self.dp)\\n        ]\\n        \\n        for i in range(1, len(self.hidden_sizes)):\\n            model.append(nn.Linear(self.hidden_sizes[i-1], self.hidden_sizes[i]))\\n            model.append(nn.ReLU())\\n            model.append(nn.Dropout(self.dp))\\n        \\n        model.append(nn.Linear(self.hidden_sizes[-1], 1))\\n        \\n        self.model = nn.Sequential(*model)\\n\\n    def forward(self, x):\\n        x = self.model(x)\\n        return x.squeeze()\\n '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_prob=0):\n",
    "        super(NN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.dp = dropout_prob\n",
    "        \n",
    "        model = [\n",
    "            nn.Linear(self.input_size, self.hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dp)\n",
    "        ]\n",
    "        \n",
    "        for i in range(1, len(self.hidden_sizes)):\n",
    "            model.append(nn.Linear(self.hidden_sizes[i-1], self.hidden_sizes[i]))\n",
    "            model.append(nn.ReLU())\n",
    "            model.append(nn.Dropout(self.dp))\n",
    "        \n",
    "        model.append(nn.Linear(self.hidden_sizes[-1], 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x.squeeze()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, hidden_sizes, dropout_prob=0):\n",
    "    model = [\n",
    "        nn.Linear(input_size, hidden_sizes[0]),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_prob)\n",
    "    ]\n",
    "    \n",
    "    for i in range(1, len(hidden_sizes)):\n",
    "        model.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "        model.append(nn.ReLU())\n",
    "        model.append(nn.Dropout(dropout_prob))\n",
    "    \n",
    "    model.append(nn.Linear(hidden_sizes[-1], 1))\n",
    "    \n",
    "    return nn.Sequential(*model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class RatingDataset(Dataset):\\n    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test):\\n        \\n        self.num_features = X_train.shape[1]\\n        \\n        self.X_train = X_train.to_numpy()\\n        self.y_train = y_train.to_numpy()\\n        self.X_val = X_val.to_numpy()\\n        self.y_val = y_val.to_numpy()\\n        self.X_test = X_test.to_numpy()\\n        self.y_test = y_test.to_numpy()\\n\\n        self.val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(self.X_val, dtype=torch.float32), torch.tensor(self.y_val, dtype=torch.float32)), batch_size=y_val.shape[0], shuffle=False)\\n        self.test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(self.X_test, dtype=torch.float32), torch.tensor(self.y_test, dtype=torch.float32)), batch_size=y_test.shape[0], shuffle=False)\\n    \\n    def get_train_loader(self, batch_size):\\n        return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(self.X_train, dtype=torch.float32), torch.tensor(self.y_train, dtype=torch.float32)), batch_size=batch_size, shuffle=True)\\n    \\n    def __len__(self):\\n        return self.X.shape[0]\\n\\n    def __getitem__(self, idx):\\n        return self.X[idx, :], self.y[idx] '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" class RatingDataset(Dataset):\n",
    "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "        \n",
    "        self.num_features = X_train.shape[1]\n",
    "        \n",
    "        self.X_train = X_train.to_numpy()\n",
    "        self.y_train = y_train.to_numpy()\n",
    "        self.X_val = X_val.to_numpy()\n",
    "        self.y_val = y_val.to_numpy()\n",
    "        self.X_test = X_test.to_numpy()\n",
    "        self.y_test = y_test.to_numpy()\n",
    "\n",
    "        self.val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(self.X_val, dtype=torch.float32), torch.tensor(self.y_val, dtype=torch.float32)), batch_size=y_val.shape[0], shuffle=False)\n",
    "        self.test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(self.X_test, dtype=torch.float32), torch.tensor(self.y_test, dtype=torch.float32)), batch_size=y_test.shape[0], shuffle=False)\n",
    "    \n",
    "    def get_train_loader(self, batch_size):\n",
    "        return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(self.X_train, dtype=torch.float32), torch.tensor(self.y_train, dtype=torch.float32)), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx, :], self.y[idx] \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('mean_rating', axis=1)\n",
    "Y = df['mean_rating']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# PCA\n",
    "pca = decomposition.PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)), batch_size=y_val.shape[0], shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)), batch_size=y_test.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hidden_size: [256, 256, 256], num_epochs: 200, batch_size: 256, learning_rate: 0.1, dropout_prob: 0.2\n",
      "Epoch: [30/200], Patience: 7, Loss: 0.0134, Val Loss: 0.01568\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[1;32m     46\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mStepLR(optimizer, step_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m model \u001b[39m=\u001b[39m train_model(model, criterion, optimizer, num_epochs, train_loader, val_loader, device, writer)\n\u001b[1;32m     50\u001b[0m mse, _, _ \u001b[39m=\u001b[39m test_model(model, criterion, test_loader, device)\n\u001b[1;32m     51\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMSE: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(mse), end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[88], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, epochs, data_loader, val_loader, device, writer)\u001b[0m\n\u001b[1;32m     13\u001b[0m data, targets \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Forward pass -> chiama la funzione forward\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m y_pred \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     16\u001b[0m \u001b[39m# Compute Loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_pred\u001b[39m.\u001b[39msqueeze(), targets)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "\"\"\" hidden_sizes = [[64, 64, 64], [128, 128, 128], [256, 256, 256], [512, 512, 512],\n",
    "                [64, 32, 64], [128, 64, 128], [256, 128, 256], [512, 256, 512],\n",
    "                [32, 64, 32], [64, 128, 64], [128, 256, 128], [256, 512, 256]] \"\"\"\n",
    "hidden_sizes = [[256, 256, 256]]\n",
    "nums_epochs = [200]\n",
    "batch_sizes = [256]\n",
    "learning_rate = [0.1]\n",
    "dropout_prob = [0.2]\n",
    "\n",
    "# crea tutte le possibili combinazioni di iperparametri\n",
    "hyperparameters = itertools.product(hidden_sizes, nums_epochs, batch_sizes, learning_rate, dropout_prob)\n",
    "\n",
    "\n",
    "\"\"\" # data\n",
    "my_dataset = RatingDataset(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "val_loader = my_dataset.val_loader\n",
    "test_loader = my_dataset.test_loader \"\"\"\n",
    "\n",
    "my_table = pd.DataFrame(columns=['hidden_size', 'num_epochs', 'batch_size', 'learning_rate', 'dropout_prob', 'MSE'])\n",
    "\n",
    "#grid search loop\n",
    "for i, [hidden_size, num_epochs, batch, learning_rate, dropout_prob] in enumerate(hyperparameters):\n",
    "    print(\"\\nhidden_size: {}, num_epochs: {}, batch_size: {}, learning_rate: {}, dropout_prob: {}\".format(hidden_size, num_epochs, batch, learning_rate, dropout_prob))\n",
    "    \n",
    "    log_name = \"dim:\"+str(hidden_size)+\"-ep:\"+str(num_epochs)+\"-bs:\"+str(batch) + \"-lr:\"+str(learning_rate)\n",
    "\n",
    "    #start tensorboard\n",
    "    writer = SummaryWriter('runs/'+log_name)\n",
    "\n",
    "    \"\"\" #changing the batch size changes the number of updates\n",
    "    train_loader = my_dataset.get_train_loader(batch)\n",
    "\n",
    "    #define architecture, loss and optimizer\n",
    "    model = NN(my_dataset.num_features, hidden_size, dropout_prob) \"\"\"\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)), batch_size=batch, shuffle=True)\n",
    "    # model = NN(X_train.shape[1], hidden_size, dropout_prob)\n",
    "    model = get_model(X_train.shape[1], hidden_size, dropout_prob)\n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    #train and validate\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    model = train_model(model, criterion, optimizer, num_epochs, train_loader, val_loader, device, writer)\n",
    "\n",
    "    mse, _, _ = test_model(model, criterion, test_loader, device)\n",
    "    print(\"MSE: {}\".format(mse), end=\"\\t\")\n",
    "\n",
    "    my_table.loc[my_table.shape[0]] = [hidden_size, num_epochs, batch, learning_rate, dropout_prob, mse.item()]\n",
    "\n",
    "    writer.add_scalar('metrics/test mse', mse.item())\n",
    "    \n",
    "    \n",
    "    \"\"\" writer.add_hparams(\n",
    "        {'lr': learning_rate, 'bsize': batch, 'dim': hidden_size, 'num_epochs': num_epochs},\n",
    "        {'hparam/mse': mse.item()}) \"\"\"\n",
    "    \n",
    "\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    torch.save(model.state_dict(), 'models/'+log_name)\n",
    "\n",
    "\n",
    "    writer.flush()\n",
    "    \n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # from my_table to csv\n",
    "my_table.to_csv('my_table.csv', index=False) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # from hyperparameters create a table\n",
    "my_table = pd.DataFrame(columns=['hidden_size', 'num_epochs', 'batch', 'learning_rate', 'mse'])\n",
    "\n",
    "mse = [0.5462421, 0.54728395, 0.54958314, 0.5459766, 0.54793584, 0.5462129, 1.3276674, 0.54908013, 0.54736763, 0.5456823, 0.54621977, 0.55039144, 984.968, 0.5463267, 0.54557204, 827.72754, 0.54591477, 0.54730576, 0.54540837, 0.5455489, 0.5542813, 5661.4873, 0.54558754, 0.590072, 67346.25, 0.5455019, 0.5475943, 0.5454466, 0.54541177, 0.54702866, 1571227400.0, 0.5457399, 0.55080384, 504163620.0, 0.54544294, 0.5582338, 0.54562855, 0.54561776, 0.58569795, 6.142842, 0.54540557, 0.5572832, 148232750.0, 0.54562014, 0.5480507, 0.5465322, 0.54691845, 0.54660344, 0.5463043, 0.5472447, 0.56238735, 39553.855, 0.5467885, 0.5461225]\n",
    "\n",
    "hidden_sizes = [8, 16, 32, 64, 128, 256]\n",
    "nums_epochs = [50]\n",
    "batch_sizes = [8, 16, 32]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "# crea tutte le possibili combinazioni di iperparametri\n",
    "hyperparameters = itertools.product(hidden_sizes, nums_epochs, batch_sizes, learning_rate)\n",
    "\n",
    "for i, [hidden_size, num_epochs, batch, learning_rate] in enumerate(hyperparameters):\n",
    "    #print(\"hidden_size: {}, num_epochs: {}, batch: {}, learning_rate: {}, mse: {}\".format(hidden_size, num_epochs, batch, learning_rate, mse[i]))\n",
    "    my_table.loc[i] = [hidden_size, num_epochs, batch, learning_rate, mse[i]]\n",
    "\n",
    "display(my_table.head())\n",
    "\n",
    "# show my_table as a table with colored mse values\n",
    "# all cells white, red if > 1, green if min\n",
    "def color_mse(val):\n",
    "    color = 'red' if val > 1 else 'white'\n",
    "    if val == my_table['mse'].min():\n",
    "        color = 'green'\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "my_table.style.applymap(color_mse, subset=['mse'])\n",
    " \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred, tag):\n",
    "    if isinstance(y_true, pd.DataFrame) or isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame) or isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.values\n",
    "    if y_true.ndim>1:\n",
    "        y_true=y_true.ravel()\n",
    "    if y_pred.ndim>1:\n",
    "        y_pred=y_pred.ravel()\n",
    "    val_acc = accuracy_score(y_true, y_pred)\n",
    "    val_f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"{tag} Acc: {val_acc} | {tag} F1: {val_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, cat_col_names, num_col_names = make_mixed_classification(n_samples=10000, n_features=20, n_categories=4)\n",
    "train_tabular, test_tabular = train_test_split(df, random_state=42)\n",
    "train_tabular, val_tabular = train_test_split(train_tabular, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.columns: ['mean_rating', 'rating_count', 'mean_timestamp', 'absurd', 'action', 'adaptation', 'adapted from:book', 'adventure', 'affectionate', 'allegory', 'art', 'atmospheric', 'bad ending', 'bad plot', 'based on a book', 'based on book', 'beautiful scenery', 'beautifully filmed', 'betrayal', 'better than expected', 'bittersweet', 'bleak', 'books', 'breathtaking', 'brutality', 'catastrophe', 'cerebral', 'chase', 'childhood', 'cinematography', 'classic car', 'clever', 'comedy', 'complex', 'computer animation', 'corruption', 'creativity', 'crime gone awry', 'criterion', 'crude humor', 'cult classic', 'cult film', 'culture clash', 'death', 'depression', 'destiny', 'dialogue', 'distopia', 'disturbing', 'downbeat', 'drama', 'dramatic', 'dreamlike', 'drinking', 'dysfunctional family', 'earnest', 'emotional', 'enigmatic', 'entertaining', 'entirely dialogue', 'excellent script', 'exceptional acting', 'existentialism', 'family', 'fantasy world', 'feel good movie', 'feel-good', 'fight scenes', 'first contact', 'friendship', 'fun', 'fun movie', 'gangsters', 'golden palm', 'good', 'good acting', 'good action', 'good soundtrack', 'great', 'great acting', 'great ending', 'great movie', 'greed', 'grindhouse', 'guilt', 'gunfight', 'happy ending', 'harsh', 'highly quotable', 'honest', 'hospital', 'humorous', 'idealism', 'identity', 'imdb top 250', 'independent film', 'insanity', 'intense', 'interesting', 'intimate', 'justice', 'life & death', 'life philosophy', 'light', 'lone hero', 'loneliness', 'love', 'love story', 'macabre', 'male nudity', 'masterpiece', 'melancholic', 'melancholy', 'mentor', 'movielens top pick', 'multiple storylines', 'murder', 'narrated', 'natural disaster', 'nocturnal', 'not funny', 'nudity (full frontal - brief)', 'nudity (full frontal - notable)', 'nudity (topless - notable)', 'obsession', 'original', 'original plot', 'oscar', 'oscar (best actress)', 'oscar (best directing)', 'oscar (best supporting actress)', 'oscar winner', 'overrated', 'passionate', 'pg-13', 'plot', 'pointless', 'police investigation', 'pornography', 'powerful ending', 'predictable', 'psychological', 'pulp', 'queer', 'quirky', 'redemption', 'reflective', 'relationships', 'revenge', 'romance', 'romantic', 'runaway', 'sacrifice', 'sci fi', 'secrets', 'sexualized violence', 'sexy', 'silly fun', 'slapstick', \"so bad it's funny\", 'social commentary', 'solitude', 'special effects', 'splatter', 'stereotypes', 'story', 'storytelling', 'stylish', 'stylized', 'suprisingly clever', 'surreal', 'suspense', 'suspenseful', 'talky', 'teen movie', 'tense', 'thought-provoking', 'touching', 'tragedy', 'transformation', 'twist ending', 'twists & turns', 'underrated', 'unfunny', 'unlikely friendships', 'unusual plot structure', 'vengeance', 'very funny', 'very good', 'very interesting', 'violence', 'violent', 'visceral', 'visual', 'visually appealing', 'visually stunning', 'weapons', 'weird', 'whimsical', 'witty', 'women', 'writers', 'IMAX', 'Film-Noir', 'year']\n",
      "continuous_columns: ['rating_count', 'mean_timestamp', 'absurd', 'action', 'adaptation', 'adapted from:book', 'adventure', 'affectionate', 'allegory', 'art', 'atmospheric', 'bad ending', 'bad plot', 'based on a book', 'based on book', 'beautiful scenery', 'beautifully filmed', 'betrayal', 'better than expected', 'bittersweet', 'bleak', 'books', 'breathtaking', 'brutality', 'catastrophe', 'cerebral', 'chase', 'childhood', 'cinematography', 'classic car', 'clever', 'comedy', 'complex', 'computer animation', 'corruption', 'creativity', 'crime gone awry', 'criterion', 'crude humor', 'cult classic', 'cult film', 'culture clash', 'death', 'depression', 'destiny', 'dialogue', 'distopia', 'disturbing', 'downbeat', 'drama', 'dramatic', 'dreamlike', 'drinking', 'dysfunctional family', 'earnest', 'emotional', 'enigmatic', 'entertaining', 'entirely dialogue', 'excellent script', 'exceptional acting', 'existentialism', 'family', 'fantasy world', 'feel good movie', 'feel-good', 'fight scenes', 'first contact', 'friendship', 'fun', 'fun movie', 'gangsters', 'golden palm', 'good', 'good acting', 'good action', 'good soundtrack', 'great', 'great acting', 'great ending', 'great movie', 'greed', 'grindhouse', 'guilt', 'gunfight', 'happy ending', 'harsh', 'highly quotable', 'honest', 'hospital', 'humorous', 'idealism', 'identity', 'imdb top 250', 'independent film', 'insanity', 'intense', 'interesting', 'intimate', 'justice', 'life & death', 'life philosophy', 'light', 'lone hero', 'loneliness', 'love', 'love story', 'macabre', 'male nudity', 'masterpiece', 'melancholic', 'melancholy', 'mentor', 'movielens top pick', 'multiple storylines', 'murder', 'narrated', 'natural disaster', 'nocturnal', 'not funny', 'nudity (full frontal - brief)', 'nudity (full frontal - notable)', 'nudity (topless - notable)', 'obsession', 'original', 'original plot', 'oscar', 'oscar (best actress)', 'oscar (best directing)', 'oscar (best supporting actress)', 'oscar winner', 'overrated', 'passionate', 'pg-13', 'plot', 'pointless', 'police investigation', 'pornography', 'powerful ending', 'predictable', 'psychological', 'pulp', 'queer', 'quirky', 'redemption', 'reflective', 'relationships', 'revenge', 'romance', 'romantic', 'runaway', 'sacrifice', 'sci fi', 'secrets', 'sexualized violence', 'sexy', 'silly fun', 'slapstick', \"so bad it's funny\", 'social commentary', 'solitude', 'special effects', 'splatter', 'stereotypes', 'story', 'storytelling', 'stylish', 'stylized', 'suprisingly clever', 'surreal', 'suspense', 'suspenseful', 'talky', 'teen movie', 'tense', 'thought-provoking', 'touching', 'tragedy', 'transformation', 'twist ending', 'twists & turns', 'underrated', 'unfunny', 'unlikely friendships', 'unusual plot structure', 'vengeance', 'very funny', 'very good', 'very interesting', 'violence', 'violent', 'visceral', 'visual', 'visually appealing', 'visually stunning', 'weapons', 'weird', 'whimsical', 'witty', 'women', 'writers', 'year']\n"
     ]
    }
   ],
   "source": [
    "label = ['mean_rating']\n",
    "# continuous_columns is df.columns - (mean_rating, IMAX, Film-Noir)\n",
    "categorical_columns = ['IMAX', 'Film-Noir']\n",
    "continuous_columns = list(df.columns)\n",
    "continuous_columns.remove('mean_rating')\n",
    "continuous_columns.remove('IMAX')\n",
    "continuous_columns.remove('Film-Noir')\n",
    "\n",
    "print('df.columns:', list(df.columns))\n",
    "print('continuous_columns:', continuous_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 16:18:58,508 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024 #Will set the same in the Trainer YAML file\n",
    "steps_per_epoch = int(train_tabular.shape[0]/1024)\n",
    "epochs = 20\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=label, #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=continuous_columns,\n",
    "    categorical_cols=categorical_columns,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(lr_scheduler=\"OneCycleLR\", lr_scheduler_params={\"max_lr\":0.00478, \"epochs\": epochs, \"steps_per_epoch\":steps_per_epoch})\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"1024-512-512\",\n",
    "    activation=\"LeakyReLU\",\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\",\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=\"trainer_config.yaml\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 16:18:58,595 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\n",
      "2023-03-17 16:18:58,600 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for regression task\n",
      "2023-03-17 16:18:59,127 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-03-17 16:18:59,239 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-03-17 16:18:59,346 - {pytorch_tabular.tabular_model:558} - INFO - Auto LR Find Started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ee16e9ca2e41649af082726e864f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=90` reached.\n",
      "LR finder stopped early after 90 steps due to diverging loss.\n",
      "Learning rate set to 0.000630957344480193\n",
      "Restoring states from the checkpoint path at /Users/biancaraimondi/Desktop/esami/DataAnalytics/progetto/data-analytics-main/.lr_find_1dec0bb2-ed59-46b7-9887-aa397012da98.ckpt\n",
      "Restored all states from the checkpoint file at /Users/biancaraimondi/Desktop/esami/DataAnalytics/progetto/data-analytics-main/.lr_find_1dec0bb2-ed59-46b7-9887-aa397012da98.ckpt\n",
      "2023-03-17 16:19:06,468 - {pytorch_tabular.tabular_model:560} - INFO - Suggested LR: 0.000630957344480193. For plot and detailed analysis, use `find_learning_rate` method.\n",
      "2023-03-17 16:19:06,470 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  999 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │    416 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │    513 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  999 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │    416 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │    513 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.0 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.0 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 4                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.0 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.0 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 4                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010b5ed8238c459e87237a49fcfdc574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 16:19:24,410 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\n",
      "2023-03-17 16:19:24,412 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x7f9d4bff1f00>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tabular_model.fit(train=train, validation=val)\n",
    "datamodule = tabular_model.prepare_dataloader(\n",
    "                train=train_tabular, validation=val_tabular, seed=42\n",
    "            )\n",
    "model = tabular_model.prepare_model(\n",
    "            datamodule\n",
    "        )\n",
    "tabular_model.train(model, datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279a093b07c947c7a1dc53819539f4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17454539239406586    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17454539239406586    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17454539239406586   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17454539239406586   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = tabular_model.evaluate(test_tabular)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98579da093c9443f936524dda68d4313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>mean_timestamp</th>\n",
       "      <th>absurd</th>\n",
       "      <th>action</th>\n",
       "      <th>adaptation</th>\n",
       "      <th>adapted from:book</th>\n",
       "      <th>adventure</th>\n",
       "      <th>affectionate</th>\n",
       "      <th>allegory</th>\n",
       "      <th>...</th>\n",
       "      <th>weapons</th>\n",
       "      <th>weird</th>\n",
       "      <th>whimsical</th>\n",
       "      <th>witty</th>\n",
       "      <th>women</th>\n",
       "      <th>writers</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>year</th>\n",
       "      <th>mean_rating_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>48</td>\n",
       "      <td>1457174951</td>\n",
       "      <td>0.08850</td>\n",
       "      <td>0.06025</td>\n",
       "      <td>0.28450</td>\n",
       "      <td>0.36050</td>\n",
       "      <td>0.09400</td>\n",
       "      <td>0.39750</td>\n",
       "      <td>0.25150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13950</td>\n",
       "      <td>0.27300</td>\n",
       "      <td>0.09675</td>\n",
       "      <td>0.11500</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>0.21725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.226767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>3.015544</td>\n",
       "      <td>193</td>\n",
       "      <td>1451186687</td>\n",
       "      <td>0.23400</td>\n",
       "      <td>0.92025</td>\n",
       "      <td>0.22600</td>\n",
       "      <td>0.17850</td>\n",
       "      <td>0.22550</td>\n",
       "      <td>0.11775</td>\n",
       "      <td>0.08150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15325</td>\n",
       "      <td>0.16025</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.19325</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.10575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.927025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>2.964286</td>\n",
       "      <td>56</td>\n",
       "      <td>1273344650</td>\n",
       "      <td>0.26475</td>\n",
       "      <td>0.28875</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>0.22450</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.16650</td>\n",
       "      <td>0.22550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40325</td>\n",
       "      <td>0.18700</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.29250</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.08875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1964</td>\n",
       "      <td>2.760783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8180</th>\n",
       "      <td>3.425719</td>\n",
       "      <td>626</td>\n",
       "      <td>1263096567</td>\n",
       "      <td>0.22275</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.42600</td>\n",
       "      <td>0.09300</td>\n",
       "      <td>0.14325</td>\n",
       "      <td>0.13225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16850</td>\n",
       "      <td>0.74050</td>\n",
       "      <td>0.13075</td>\n",
       "      <td>0.19225</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.38600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>3.156011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10584</th>\n",
       "      <td>3.130631</td>\n",
       "      <td>111</td>\n",
       "      <td>1401808349</td>\n",
       "      <td>0.49450</td>\n",
       "      <td>0.15225</td>\n",
       "      <td>0.32600</td>\n",
       "      <td>0.24625</td>\n",
       "      <td>0.11575</td>\n",
       "      <td>0.67550</td>\n",
       "      <td>0.19525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30050</td>\n",
       "      <td>0.32475</td>\n",
       "      <td>0.83400</td>\n",
       "      <td>0.44775</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>0.38725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.901919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_rating  rating_count  mean_timestamp   absurd   action  \\\n",
       "10897     3.625000            48      1457174951  0.08850  0.06025   \n",
       "9044      3.015544           193      1451186687  0.23400  0.92025   \n",
       "7335      2.964286            56      1273344650  0.26475  0.28875   \n",
       "8180      3.425719           626      1263096567  0.22275  0.07325   \n",
       "10584     3.130631           111      1401808349  0.49450  0.15225   \n",
       "\n",
       "       adaptation  adapted from:book  adventure  affectionate  allegory  ...  \\\n",
       "10897     0.28450            0.36050    0.09400       0.39750   0.25150  ...   \n",
       "9044      0.22600            0.17850    0.22550       0.11775   0.08150  ...   \n",
       "7335      0.21000            0.22450    0.38500       0.16650   0.22550  ...   \n",
       "8180      0.50625            0.42600    0.09300       0.14325   0.13225  ...   \n",
       "10584     0.32600            0.24625    0.11575       0.67550   0.19525  ...   \n",
       "\n",
       "       weapons    weird  whimsical    witty   women  writers  IMAX  Film-Noir  \\\n",
       "10897  0.13950  0.27300    0.09675  0.11500  0.8065  0.21725     0          0   \n",
       "9044   0.15325  0.16025    0.12600  0.19325  0.1360  0.10575     0          0   \n",
       "7335   0.40325  0.18700    0.10400  0.29250  0.0875  0.08875     0          0   \n",
       "8180   0.16850  0.74050    0.13075  0.19225  0.2330  0.38600     0          0   \n",
       "10584  0.30050  0.32475    0.83400  0.44775  0.7895  0.38725     0          0   \n",
       "\n",
       "       year  mean_rating_prediction  \n",
       "10897  2010                3.226767  \n",
       "9044   2007                2.927025  \n",
       "7335   1964                2.760783  \n",
       "8180   2005                3.156011  \n",
       "10584  2010                2.901919  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(test_tabular)\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_metrics(test[label], pred_df[\"prediction\"], tag=\"Holdout\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model.save_model(\"examples/basic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 16:19:26,248 - {pytorch_tabular.tabular_model:126} - INFO - Experiment Tracking is turned off\n",
      "2023-03-17 16:19:26,252 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "loaded_model = TabularModel.load_from_checkpoint(\"examples/basic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce0ac8aa04f42a4a9c102a718d77e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17454539239406586    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.17454539239406586    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17454539239406586   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.17454539239406586   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = loaded_model.evaluate(test_tabular)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce5a35b82e3a4a7572376ce546f2ed9882e8aef9bb5481274d0fa465e4956b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
